{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1  Introduction\n",
    "## 1.1.1  About This Experiment\n",
    "- This experiment helps trainees understand the basic syntax of TensorFlow 2.x by introducing a series of tensor operations of TensorFlow 2.x, including tensor creation, slicing, and indexing, tensor dimension modification, tensor arithmetic operations, and tensor sorting.\n",
    "\n",
    "## 1.1.2  Objectives\n",
    "- Upon completion of this task, you will be able to:\n",
    "  - Understand how to create a tensor.\n",
    "  - Master the tensor slicing and indexing methods.\n",
    "  - Master the syntax for tensor dimension modification.\n",
    "  - Master arithmetic operations of tensors.\n",
    "  - Master the tensor sorting method.\n",
    "  - Dive deeper into eager execution and AutoGraph based on code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 1.2 Experiment Steps \n",
    "## 1.2.1 Introduction to Tensors \n",
    "- In TensorFlow, tensors are classified into constant tensors and variable tensors. \n",
    "  - A defined constant tensor has an unchangeable value and dimension, and a defined variable tensor has a changeable value and an unchangeable dimension. \n",
    "  - In neural networks, variable tensors are generally used as matrices for storing weights and other information, and are a type of trainable data. Constant tensors can be used as variables for storing hyperparameters or other structured data. \n",
    "\n",
    "### 1.2.1.1  Tensor Creation\n",
    "#### 1.2.1.1.1  Creating a Constant Tensor\n",
    "- Common methods for creating a constant tensor include:\n",
    "  - tf.constant(): creates a constant tensor.\n",
    "  - tf.zeros(), tf.zeros_like(), tf.ones(), and tf.ones_like(): create an all-zero or all-one constant tensor.\n",
    "  - tf.fill(): creates a tensor with a user-defined value.\n",
    "  - tf.random: creates a tensor with a known distribution.\n",
    "- Creating a list object by using NumPy, and then converting the list object into a tensor by using tf.convert_to_tensor.\n",
    "\n",
    "Step 1: tf.constant() \n",
    "- tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False):\n",
    "  - value: value\n",
    "  - dtype: data type\n",
    "  - shape: tensor shape\n",
    "  - name: constant name\n",
    "  - verify_shape: Boolean value, used to verify the shape of a value. The default value is False. If verify_shape is set to True, the system checks whether the shape of a value is consistent with the value of shape. If they are inconsistent, the system reports an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_a = tf.constant(\n",
    "    [1, 2, 3, 4,5,6], shape=[3, 2], dtype=tf.float32\n",
    ")  # Create a 2x2 matrix with values 1, 2, 3, and 4.\n",
    "const_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of the constant const_a: [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "data type of the constant const_a: <dtype: 'float32'>\n",
      "shape of the constant const_a: (3, 2)\n",
      "name of the device that is to generate the constant const_a: /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"value of the constant const_a:\", const_a.numpy())\n",
    "print(\"data type of the constant const_a:\", const_a.dtype)\n",
    "print(\"shape of the constant const_a:\", const_a.shape)\n",
    "print(\"name of the device that is to generate the constant const_a:\", const_a.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Step 2: tf.zeros(), tf.zeros_like(), tf.ones(), and tf.ones_like()\n",
    "- Usages of tf.ones() and tf.ones_like() are similar to those of tf.zeros() and tf.zeros_like(). Therefore, the following describes only the usages of tf.ones() and tf.ones_like().\n",
    "- Create a constant with the value 0.\n",
    "  - tf.zeros(shape, dtype=tf.float32, name=None):\n",
    "    - shape: tensor shape\n",
    "    - dtype: data type\n",
    "    - name: constant name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_b = tf.zeros(\n",
    "    shape=[3, 3], dtype=tf.int32\n",
    ")  # Create a 2x3 matrix with all values being 0.\n",
    "zeros_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "- Create a tensor whose value is 0 based on the input tensor, with its shape being the same as that of the input tensor. \n",
    "  - tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True):\n",
    "    - input_tensor: tensor\n",
    "    - dtype: data type\n",
    "    - name: tensor name\n",
    "    - optimize: indicates whether optimization is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_like_c = tf.zeros_like(const_a)\n",
    "zeros_like_c.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: tf.fill()\n",
    "- Create a tensor and fill it with a specific value. \n",
    "  - tf.fill(dims, value, name=None):\n",
    "    - dims: tensor shape, same as shape above.\n",
    "    - value: tensor value\n",
    "    - name: tensor name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 10, 10, 10],\n",
       "       [10, 10, 10, 10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_d = tf.fill([2, 4], 10)  # Create a 2x3 matrix with all values being 8.\n",
    "fill_d.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: tf.random\n",
    "- This module is used to generate a tensor with a specific distribution. Common methods in this module include tf.random.uniform(), tf.random.normal(), and tf.random.shuffle(). The following describes how to use tf.random.normal().\n",
    "- Create a tensor that conforms to a normal distribution. \n",
    "  - tf.random.normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32,seed=None, name=None):\n",
    "    - shape: data shape\n",
    "    - mean: mean value with a Gaussian distribution\n",
    "    - stddev: standard deviation with a Gaussian distribution\n",
    "    - dtype: data type\n",
    "    - seed: random seed\n",
    "    - name: tensor name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1886816, 6.4845986, 5.0653296],\n",
       "       [2.5572958, 5.0992484, 5.591224 ],\n",
       "       [5.592823 , 2.8770704, 4.277103 ],\n",
       "       [4.9437294, 5.6435447, 4.735676 ],\n",
       "       [6.856633 , 5.5678415, 4.617164 ],\n",
       "       [3.5146565, 6.261771 , 4.974694 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_e = tf.random.normal([6, 3], mean=5, stddev=1.0, seed=1)\n",
    "random_e.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Step 5 Create a list object by using NumPy, and then convert the list object into a tensor by using tf.convert_to_tensor.\n",
    "- This method can convert a given value into a tensor. tf.convert_to_tensor can be used to convert a Python data type into a tensor data type available to TensorFlow.\n",
    "  - tf.convert_to_tensor(value,dtype=None,dtype_hint=None,name=None):\n",
    "    - value: value to be converted\n",
    "    - dtype: data type of the tensor\n",
    "    - dtype_hint: optional element type for the returned tensor, used when dtype is set to None. In some cases, a caller may not consider dtype when calling tf.convert_to_tensor. Therefore, dtype_hint can be used as a preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list.\n",
    "list_f = [1, 2, 3, 4, 5, 6,9]\n",
    "# View the data type.\n",
    "type(list_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "##### 1.2.1.1.2  Creating a Variable Tensor\n",
    "In TensorFlow, variables are operated using the tf.Variable class. tf.Variable indicates a tensor. The value of tf.Variable can be changed by running an arithmetic operation on tf.Variable. Variable values can be read and changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_f = tf.convert_to_tensor(list_f, dtype=tf.float32)\n",
    "tensor_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a variable. Only the initial value needs to be provided.\n",
    "var_1 = tf.Variable(4*tf.ones(2,3))\n",
    "var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the variable var_1: tf.Tensor(\n",
      "[[4. 4. 4.]\n",
      " [4. 4. 4.]\n",
      " [4. 4. 4.]\n",
      " [4. 4. 4.]\n",
      " [4. 4. 4.]], shape=(5, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (5, 3) and (2, 3) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-f34aecc462ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Assign a variable value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvar_value_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvar_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_value_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Value of the variable var_1 after the assignment:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m    860\u001b[0m           self.handle, value_tensor, name=name)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \"\"\"\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (5, 3) and (2, 3) are incompatible"
     ]
    }
   ],
   "source": [
    "# Read the variable value.\n",
    "print(\"Value of the variable var_1:\", var_1.read_value())\n",
    "# Assign a variable value.\n",
    "var_value_1 = [[1, 2, 3], [4, 5, 6]]\n",
    "var_1.assign(var_value_1)\n",
    "print(\"Value of the variable var_1 after the assignment:\", var_1.read_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[2., 3., 4.],\n",
       "       [5., 6., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable addition\n",
    "var_1.assign_add(tf.ones([2, 3]))\n",
    "var_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "### 1.2.1.2  Tensor Slicing and Indexing\n",
    "#### 1.2.1.2.1  Slicing\n",
    "- Tensor slicing methods include:\n",
    "  - [start: end]: extracts a data slice from the start position to the end position of the tensor.\n",
    "  - [start:end:step] or [::step]: extracts a data slice at an interval of step from the start position to the end position of the tensor.\n",
    "  - [::-1]: slices data from the last element.\n",
    "  - '...': indicates a data slice of any length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Create a 4-dimensional tensor. The tensor contains four images. The size of each image is 100 x 100 x 3.\n",
    "tensor_h = tf.random.normal([2,3,4])\n",
    "tensor_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 100, 100, 3), dtype=float32, numpy=\n",
       "array([[[[ 0.3264129 ,  0.27895576, -0.9666431 ],\n",
       "         [-0.28996465,  0.7546892 ,  1.9307919 ],\n",
       "         [-0.34496933, -1.2426192 ,  1.2129008 ],\n",
       "         ...,\n",
       "         [-0.6952881 , -1.4162931 , -0.43920645],\n",
       "         [-1.0463091 , -1.5944855 ,  0.29268524],\n",
       "         [ 1.7662923 ,  0.34818107, -0.19025818]],\n",
       "\n",
       "        [[ 0.52402717,  0.01378755, -0.08374947],\n",
       "         [ 0.5785747 ,  0.6589598 ,  0.07612512],\n",
       "         [-0.8770482 , -2.352875  , -0.22594248],\n",
       "         ...,\n",
       "         [-0.714165  , -0.12942502,  0.06598176],\n",
       "         [-1.0150676 ,  0.5746088 , -1.6364552 ],\n",
       "         [ 0.73780537,  0.01828147,  1.1737319 ]],\n",
       "\n",
       "        [[ 0.4823744 , -0.4834205 , -0.5923167 ],\n",
       "         [ 0.5422618 ,  1.1718302 ,  0.8359285 ],\n",
       "         [-1.1451828 ,  2.7692719 , -0.40657797],\n",
       "         ...,\n",
       "         [ 0.25345445,  1.0488224 ,  0.7047369 ],\n",
       "         [ 2.097427  ,  0.9483373 , -0.85790074],\n",
       "         [-1.3152928 , -0.06999412,  0.12434947]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.7707629 , -0.3821464 ,  0.19299135],\n",
       "         [ 0.13561147, -1.3612344 ,  0.8168715 ],\n",
       "         [-0.21365617,  1.1271193 , -0.31804517],\n",
       "         ...,\n",
       "         [-0.60432506,  0.31473795, -0.11268552],\n",
       "         [-1.1143806 , -0.6442453 , -0.1006491 ],\n",
       "         [ 1.3287668 , -0.6537866 , -1.2700552 ]],\n",
       "\n",
       "        [[ 0.14598897, -1.5980966 , -0.5034572 ],\n",
       "         [-1.8344911 , -0.49202457, -0.85222   ],\n",
       "         [-1.4576734 ,  0.8344678 ,  0.8091997 ],\n",
       "         ...,\n",
       "         [-1.8299011 , -0.33173713,  0.08688804],\n",
       "         [ 0.31977904, -0.81838596, -0.24982075],\n",
       "         [ 0.49994653,  0.9520037 , -0.21400428]],\n",
       "\n",
       "        [[-0.9914604 , -0.68254066, -0.27809802],\n",
       "         [-0.36974847, -0.22413097,  0.9398748 ],\n",
       "         [-0.7943329 ,  0.06687992, -0.02101246],\n",
       "         ...,\n",
       "         [-0.26259112, -0.69045675, -1.7044258 ],\n",
       "         [-0.68313617, -1.7743827 , -0.4766962 ],\n",
       "         [-0.32830602,  0.05604719, -1.2359772 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.1729376 ,  0.12987177,  1.3100237 ],\n",
       "         [ 0.7705828 , -0.5379639 ,  1.23652   ],\n",
       "         [ 0.35666764, -0.30412912,  0.03192582],\n",
       "         ...,\n",
       "         [-0.6268707 ,  0.55047923, -0.91222686],\n",
       "         [-1.0468419 , -0.29599193,  0.91044855],\n",
       "         [-0.865859  , -0.23101088, -0.96602476]],\n",
       "\n",
       "        [[ 1.4410032 ,  1.949332  , -0.05488059],\n",
       "         [ 1.0284817 , -0.49673   ,  0.92629   ],\n",
       "         [-0.16013613, -0.7061752 ,  0.7676486 ],\n",
       "         ...,\n",
       "         [-0.99834114, -1.046762  ,  1.1323372 ],\n",
       "         [ 1.1334797 ,  1.8503807 , -0.43565255],\n",
       "         [ 1.2582943 ,  1.0068763 ,  0.75224847]],\n",
       "\n",
       "        [[ 0.5925799 ,  2.2157357 , -2.2854788 ],\n",
       "         [-1.167507  ,  1.7194507 ,  1.0763777 ],\n",
       "         [ 0.1631658 ,  1.9603652 ,  0.09836569],\n",
       "         ...,\n",
       "         [ 0.6783202 , -1.1881564 ,  0.72481734],\n",
       "         [ 2.0843546 , -0.6960661 , -0.15942946],\n",
       "         [ 0.88436544,  0.01145436, -0.80060166]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.93552864,  0.63768274, -0.00520164],\n",
       "         [ 0.15919207,  0.01691433,  0.5571921 ],\n",
       "         [ 0.6087084 , -1.1172768 , -0.42072657],\n",
       "         ...,\n",
       "         [-0.32584006, -0.17149666,  0.3643538 ],\n",
       "         [-2.502067  , -1.0060486 , -1.2240047 ],\n",
       "         [ 1.8438057 , -0.23298192,  0.36736304]],\n",
       "\n",
       "        [[-0.62720764,  0.38155675,  1.0296983 ],\n",
       "         [ 0.3439386 , -0.52749944, -0.08565173],\n",
       "         [-0.9201765 ,  0.38227963, -0.15778913],\n",
       "         ...,\n",
       "         [ 0.70350796,  0.4004978 ,  0.62465245],\n",
       "         [-0.494281  , -0.48181063, -0.5434168 ],\n",
       "         [-1.1778727 , -1.4605334 ,  1.0950174 ]],\n",
       "\n",
       "        [[-0.3945992 ,  0.17663784,  0.5200521 ],\n",
       "         [ 0.98604417,  1.0866233 ,  0.15019222],\n",
       "         [ 0.8368001 ,  0.3082596 , -0.25811133],\n",
       "         ...,\n",
       "         [-1.4137418 , -0.69450444, -0.7173936 ],\n",
       "         [-0.6789864 , -1.1627976 , -0.64057547],\n",
       "         [-3.036527  ,  0.3811173 , -0.2958802 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.6123424 ,  0.23414701,  0.25191483],\n",
       "         [-0.5247983 ,  0.02538384, -1.1788392 ],\n",
       "         [-0.19300258, -0.26835153, -0.62958664],\n",
       "         ...,\n",
       "         [ 0.27473187,  0.19388816,  0.12079503],\n",
       "         [ 0.6517643 ,  0.794949  , -0.49118048],\n",
       "         [ 0.05124056,  0.8352903 ,  2.0728414 ]],\n",
       "\n",
       "        [[-0.16558008, -1.7209821 ,  0.54092824],\n",
       "         [ 0.25341728, -0.3728979 ,  0.02283656],\n",
       "         [ 0.381061  , -0.44437352, -2.5004454 ],\n",
       "         ...,\n",
       "         [-0.59778106, -1.5259322 , -0.09589908],\n",
       "         [ 0.7199513 ,  0.77361035,  0.14499386],\n",
       "         [-0.6522267 , -1.0167317 , -0.27159336]],\n",
       "\n",
       "        [[ 0.5022943 ,  1.5812405 , -3.5802133 ],\n",
       "         [ 0.4176576 , -2.2152605 , -1.4889185 ],\n",
       "         [ 0.5621797 ,  1.1409361 , -0.6326163 ],\n",
       "         ...,\n",
       "         [ 0.15774867, -0.15873219,  0.10663814],\n",
       "         [ 1.9833295 ,  0.1577049 , -0.1763799 ],\n",
       "         [ 0.4321895 ,  0.6447027 ,  1.1505896 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.4535123 , -1.4240546 , -1.8445203 ],\n",
       "         [ 0.3411192 ,  0.12846161,  0.42478085],\n",
       "         [-0.5984657 , -0.8146117 ,  0.6016706 ],\n",
       "         ...,\n",
       "         [ 0.34095526,  0.29368636, -1.1927965 ],\n",
       "         [ 0.23319815,  1.213739  ,  2.5787117 ],\n",
       "         [ 0.90750253, -1.2991384 ,  0.17390972]],\n",
       "\n",
       "        [[-0.25558206,  0.5897132 , -0.8478063 ],\n",
       "         [ 0.97269547,  0.7939702 , -0.82456523],\n",
       "         [-0.36918122, -0.16762365,  0.15273556],\n",
       "         ...,\n",
       "         [-0.94223785, -0.03786672,  0.32950288],\n",
       "         [ 0.7654489 , -1.1177934 , -2.1039917 ],\n",
       "         [-1.5873445 ,  1.203603  , -1.0358052 ]],\n",
       "\n",
       "        [[ 0.57227665, -0.28302902,  1.3386792 ],\n",
       "         [ 0.6431277 ,  1.2924986 ,  0.09889685],\n",
       "         [ 0.9533684 ,  1.2283926 , -0.57181066],\n",
       "         ...,\n",
       "         [ 1.1602187 ,  0.6828103 ,  1.579233  ],\n",
       "         [-0.5553507 ,  0.10728125, -1.0815554 ],\n",
       "         [-0.58754194, -0.17625616, -1.3178368 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.13556789,  0.6946535 ,  1.0119388 ],\n",
       "         [ 1.0285369 , -0.67084485, -1.0763637 ],\n",
       "         [-0.3007773 ,  0.35218492, -0.24793571],\n",
       "         ...,\n",
       "         [-1.0689595 ,  0.6422869 , -0.16725256],\n",
       "         [ 1.3330636 ,  0.6707112 , -0.65406066],\n",
       "         [-0.49931118,  0.97790027,  0.5979258 ]],\n",
       "\n",
       "        [[-1.070846  , -0.66348106, -0.50829405],\n",
       "         [ 0.73878163,  1.1814032 , -0.52086514],\n",
       "         [-1.3692003 , -0.34706303,  0.86418146],\n",
       "         ...,\n",
       "         [ 0.40705794, -0.3374544 ,  0.23752421],\n",
       "         [-0.23725359,  0.03683858, -0.9906588 ],\n",
       "         [-0.21804303, -1.2436489 ,  1.5942947 ]],\n",
       "\n",
       "        [[-1.1107581 ,  0.96535486,  1.0523945 ],\n",
       "         [ 0.75432765, -0.6395213 , -0.33340505],\n",
       "         [ 2.167442  ,  0.58920234, -0.9316525 ],\n",
       "         ...,\n",
       "         [-0.15194523,  0.35071558,  0.50804704],\n",
       "         [ 1.2578727 ,  1.7105575 , -1.6372516 ],\n",
       "         [-1.3377458 , -0.19692142, -0.18634196]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.26134002,  2.0338688 , -0.51555556],\n",
       "         [ 0.5689745 ,  0.0230819 , -1.0696607 ],\n",
       "         [-0.70635045,  0.23927142, -0.801269  ],\n",
       "         ...,\n",
       "         [ 0.88201845,  0.5217553 , -0.42358893],\n",
       "         [-1.231312  ,  0.8373589 ,  0.6822516 ],\n",
       "         [-1.1430196 ,  0.68260205, -1.5540998 ]],\n",
       "\n",
       "        [[ 0.68100685,  0.36470318, -1.8541158 ],\n",
       "         [-0.65621865, -0.5096578 , -1.1040165 ],\n",
       "         [-1.2606361 ,  1.0576618 , -0.20738132],\n",
       "         ...,\n",
       "         [ 1.0598165 ,  1.3024455 , -0.604524  ],\n",
       "         [ 0.6620577 , -0.55247134, -1.0320237 ],\n",
       "         [-0.35842365,  0.5699635 ,  0.27613094]],\n",
       "\n",
       "        [[-0.0119664 ,  1.6458237 ,  0.04505084],\n",
       "         [ 1.5382367 ,  0.3976145 ,  0.09265053],\n",
       "         [ 0.29754016,  1.9479827 ,  0.23078443],\n",
       "         ...,\n",
       "         [-0.21681494, -0.7956198 , -0.82230574],\n",
       "         [ 1.5281438 , -0.91762125, -0.7901161 ],\n",
       "         [-0.6445457 , -0.08370595, -0.04692995]]]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_h = tf.random.normal([4,100,100,3])\n",
    "tensor_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 0.6384951 ,  0.6191002 , -1.371334  ],\n",
       "       [ 0.48717734, -0.29717663, -0.26878172]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first image.\n",
    "tensor_h[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 4), dtype=float32, numpy=\n",
       "array([[[-0.1815408 ,  1.6070951 ,  1.7767813 ,  0.07453974],\n",
       "        [-0.5905525 , -0.65095484, -0.17399302,  0.7154641 ],\n",
       "        [ 0.305217  , -1.4403421 , -1.0302207 , -0.33325818]],\n",
       "\n",
       "       [[-0.9295179 ,  0.21188092, -0.4256927 ,  0.88601035],\n",
       "        [ 0.02976389,  0.9278227 , -0.19514447, -1.0209032 ],\n",
       "        [ 0.9398715 ,  0.3682283 , -0.25325668, -0.38929498]],\n",
       "\n",
       "       [[-1.3547077 , -0.78513145, -0.61368626,  0.89923984],\n",
       "        [ 0.42976606, -0.71911347, -0.0470489 ,  0.3842623 ],\n",
       "        [-0.7699318 , -1.0182682 ,  2.416296  ,  0.6309644 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract one slice at an interval of two images.\n",
    "tensor_h[::1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 4), dtype=float32, numpy=\n",
       "array([[[-1.3547077 , -0.78513145, -0.61368626,  0.89923984],\n",
       "        [ 0.42976606, -0.71911347, -0.0470489 ,  0.3842623 ],\n",
       "        [-0.7699318 , -1.0182682 ,  2.416296  ,  0.6309644 ]],\n",
       "\n",
       "       [[-0.9295179 ,  0.21188092, -0.4256927 ,  0.88601035],\n",
       "        [ 0.02976389,  0.9278227 , -0.19514447, -1.0209032 ],\n",
       "        [ 0.9398715 ,  0.3682283 , -0.25325668, -0.38929498]],\n",
       "\n",
       "       [[-0.1815408 ,  1.6070951 ,  1.7767813 ,  0.07453974],\n",
       "        [-0.5905525 , -0.65095484, -0.17399302,  0.7154641 ],\n",
       "        [ 0.305217  , -1.4403421 , -1.0302207 , -0.33325818]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice data from the last element.\n",
    "tensor_h[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### 1.2.1.2.2  Indexing\n",
    "The basic format of an index is a[d1][d2][d3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-1.3538269>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the pixel in the position [20,40] in the second channel of the first image.\n",
    "tensor_h[0][19][39][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "- If the indexes of data to be extracted are nonconsecutive, tf.gather and tf.gather_nd are commonly used for data extraction in TensorFlow.\n",
    "- To extract data from a particular dimension: \n",
    "  - tf.gather(params, indices,axis=None):\n",
    "    - params: input tensor\n",
    "    - indices: index of the data to be extracted\n",
    "    - axis: dimension of the data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 100, 100, 3), dtype=float32, numpy=\n",
       "array([[[[ 0.3264129 ,  0.27895576, -0.9666431 ],\n",
       "         [-0.28996465,  0.7546892 ,  1.9307919 ],\n",
       "         [-0.34496933, -1.2426192 ,  1.2129008 ],\n",
       "         ...,\n",
       "         [-0.6952881 , -1.4162931 , -0.43920645],\n",
       "         [-1.0463091 , -1.5944855 ,  0.29268524],\n",
       "         [ 1.7662923 ,  0.34818107, -0.19025818]],\n",
       "\n",
       "        [[ 0.52402717,  0.01378755, -0.08374947],\n",
       "         [ 0.5785747 ,  0.6589598 ,  0.07612512],\n",
       "         [-0.8770482 , -2.352875  , -0.22594248],\n",
       "         ...,\n",
       "         [-0.714165  , -0.12942502,  0.06598176],\n",
       "         [-1.0150676 ,  0.5746088 , -1.6364552 ],\n",
       "         [ 0.73780537,  0.01828147,  1.1737319 ]],\n",
       "\n",
       "        [[ 0.4823744 , -0.4834205 , -0.5923167 ],\n",
       "         [ 0.5422618 ,  1.1718302 ,  0.8359285 ],\n",
       "         [-1.1451828 ,  2.7692719 , -0.40657797],\n",
       "         ...,\n",
       "         [ 0.25345445,  1.0488224 ,  0.7047369 ],\n",
       "         [ 2.097427  ,  0.9483373 , -0.85790074],\n",
       "         [-1.3152928 , -0.06999412,  0.12434947]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.7707629 , -0.3821464 ,  0.19299135],\n",
       "         [ 0.13561147, -1.3612344 ,  0.8168715 ],\n",
       "         [-0.21365617,  1.1271193 , -0.31804517],\n",
       "         ...,\n",
       "         [-0.60432506,  0.31473795, -0.11268552],\n",
       "         [-1.1143806 , -0.6442453 , -0.1006491 ],\n",
       "         [ 1.3287668 , -0.6537866 , -1.2700552 ]],\n",
       "\n",
       "        [[ 0.14598897, -1.5980966 , -0.5034572 ],\n",
       "         [-1.8344911 , -0.49202457, -0.85222   ],\n",
       "         [-1.4576734 ,  0.8344678 ,  0.8091997 ],\n",
       "         ...,\n",
       "         [-1.8299011 , -0.33173713,  0.08688804],\n",
       "         [ 0.31977904, -0.81838596, -0.24982075],\n",
       "         [ 0.49994653,  0.9520037 , -0.21400428]],\n",
       "\n",
       "        [[-0.9914604 , -0.68254066, -0.27809802],\n",
       "         [-0.36974847, -0.22413097,  0.9398748 ],\n",
       "         [-0.7943329 ,  0.06687992, -0.02101246],\n",
       "         ...,\n",
       "         [-0.26259112, -0.69045675, -1.7044258 ],\n",
       "         [-0.68313617, -1.7743827 , -0.4766962 ],\n",
       "         [-0.32830602,  0.05604719, -1.2359772 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.13556789,  0.6946535 ,  1.0119388 ],\n",
       "         [ 1.0285369 , -0.67084485, -1.0763637 ],\n",
       "         [-0.3007773 ,  0.35218492, -0.24793571],\n",
       "         ...,\n",
       "         [-1.0689595 ,  0.6422869 , -0.16725256],\n",
       "         [ 1.3330636 ,  0.6707112 , -0.65406066],\n",
       "         [-0.49931118,  0.97790027,  0.5979258 ]],\n",
       "\n",
       "        [[-1.070846  , -0.66348106, -0.50829405],\n",
       "         [ 0.73878163,  1.1814032 , -0.52086514],\n",
       "         [-1.3692003 , -0.34706303,  0.86418146],\n",
       "         ...,\n",
       "         [ 0.40705794, -0.3374544 ,  0.23752421],\n",
       "         [-0.23725359,  0.03683858, -0.9906588 ],\n",
       "         [-0.21804303, -1.2436489 ,  1.5942947 ]],\n",
       "\n",
       "        [[-1.1107581 ,  0.96535486,  1.0523945 ],\n",
       "         [ 0.75432765, -0.6395213 , -0.33340505],\n",
       "         [ 2.167442  ,  0.58920234, -0.9316525 ],\n",
       "         ...,\n",
       "         [-0.15194523,  0.35071558,  0.50804704],\n",
       "         [ 1.2578727 ,  1.7105575 , -1.6372516 ],\n",
       "         [-1.3377458 , -0.19692142, -0.18634196]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.26134002,  2.0338688 , -0.51555556],\n",
       "         [ 0.5689745 ,  0.0230819 , -1.0696607 ],\n",
       "         [-0.70635045,  0.23927142, -0.801269  ],\n",
       "         ...,\n",
       "         [ 0.88201845,  0.5217553 , -0.42358893],\n",
       "         [-1.231312  ,  0.8373589 ,  0.6822516 ],\n",
       "         [-1.1430196 ,  0.68260205, -1.5540998 ]],\n",
       "\n",
       "        [[ 0.68100685,  0.36470318, -1.8541158 ],\n",
       "         [-0.65621865, -0.5096578 , -1.1040165 ],\n",
       "         [-1.2606361 ,  1.0576618 , -0.20738132],\n",
       "         ...,\n",
       "         [ 1.0598165 ,  1.3024455 , -0.604524  ],\n",
       "         [ 0.6620577 , -0.55247134, -1.0320237 ],\n",
       "         [-0.35842365,  0.5699635 ,  0.27613094]],\n",
       "\n",
       "        [[-0.0119664 ,  1.6458237 ,  0.04505084],\n",
       "         [ 1.5382367 ,  0.3976145 ,  0.09265053],\n",
       "         [ 0.29754016,  1.9479827 ,  0.23078443],\n",
       "         ...,\n",
       "         [-0.21681494, -0.7956198 , -0.82230574],\n",
       "         [ 1.5281438 , -0.91762125, -0.7901161 ],\n",
       "         [-0.6445457 , -0.08370595, -0.04692995]]]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first, second, and fourth images from tensor_h ([4,100,100,3]).\n",
    "indices = [0, 3]\n",
    "tf.gather(tensor_h, axis=0, indices=indices, batch_dims=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "tf.gather_nd allows data extraction from multiple dimensions:\n",
    "- tf.gather_nd(params,indices):\n",
    "  - params: input tensor\n",
    "  - indices: indexes of the data to be extracted, which is generally a multidimensional list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-1.3956844 ,  0.38977048], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the pixel in [1,1] from the first dimension of the first image and the pixel in [2,2] from the first dimension of the second image in tensot_h ([4,100,100,3]).\n",
    "indices = [[0, 1, 1, 0], [1, 2, 2, 0]]\n",
    "# Understand that we have (samples, image) where image is (100, 100, 3)\n",
    "# So with [0, 1, 1, 0] we get (0, (1, 1, 0)) or tensor_h[0, 1, 1, 0]\n",
    "# And with [1, 2, 2, 0] we get (1, (2, 2, 0)) or tensor_h[1, 2, 2, 0]\n",
    "tf.gather_nd(tensor_h, indices=indices)  # With this method we get them at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "### 1.2.1.3  Tensor Dimension Modification\n",
    "#### 1.2.1.3.1  Dimension Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 3)\n",
      "tf.Tensor([2 3], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "const_d_1 = tf.constant([[1, 2, 3, 4,5,6]], shape=[2, 3], dtype=tf.float32)\n",
    "# Three common methods for displaying a dimension:\n",
    "print(const_d_1.shape)\n",
    "print(const_d_1.get_shape())\n",
    "print(\n",
    "    tf.shape(const_d_1)\n",
    ")  # The output is a tensor. The value of the tensor indicates the size of the tensor dimension to be displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, .shape and .get_shape() return TensorShape objects, and tf.shape(x) returns Tensor objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### 1.2.1.3.2  Dimension Reshaping\n",
    "- tf.reshape(tensor,shape,name=None):\n",
    "  - tensor: input tensor\n",
    "  - shape: dimension of the reshaped tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(reshape_1)\n",
    "tf.reshape(reshape_1, (3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### 1.2.1.3.3  Dimension Expansion\n",
    "- tf.expand_dims(input,axis,name=None):\n",
    "  - input: input tensor\n",
    "  - axis: adds a dimension after the axis dimension. When the number of dimensions of the input data is D, the axis must fall in the range of [–(D + 1), D] (included). A negative value indicates adding a dimension in reverse order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### 1.2.1.3.4  Dimension Squeezing\n",
    "- tf.squeeze(input,axis=None,name=None):\n",
    "  - input: input tensor\n",
    "  - axis: If axis is set to 1, dimension 1 needs to be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (100, 100, 3)\n",
      "add a dimension before the first dimension (axis = 0):  (1, 100, 100, 3)\n",
      "add a dimension before the second dimension (axis = 1):  (100, 1, 100, 3)\n",
      "add a dimension after the last dimension (axis = –1):  (100, 100, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image.\n",
    "expand_sample_1 = tf.random.normal([100, 100, 3], seed=1)\n",
    "print(\"size of the original data:\", expand_sample_1.shape)\n",
    "print(\n",
    "    \"add a dimension before the first dimension (axis = 0): \",\n",
    "    tf.expand_dims(expand_sample_1, axis=0).shape,\n",
    ")\n",
    "print(\n",
    "    \"add a dimension before the second dimension (axis = 1): \",\n",
    "    tf.expand_dims(expand_sample_1, axis=1).shape,\n",
    ")\n",
    "print(\n",
    "    \"add a dimension after the last dimension (axis = –1): \",\n",
    "    tf.expand_dims(expand_sample_1, axis=-1).shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### 1.2.1.3.5  Transpose\n",
    "- tf.transpose(a,perm=None,conjugate=False,name='transpose'):\n",
    "  - a: input tensor\n",
    "  - perm: tensor size sequence, generally used to transpose high-dimensional arrays\n",
    "  - conjugate: indicates complex number transpose.\n",
    "  - name: tensor name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (1, 100, 100, 3)\n",
      "data size after dimension squeezing: (100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image.\n",
    "squeeze_sample_1 = tf.random.normal([1, 100, 100, 3])\n",
    "print(\"size of the original data:\", squeeze_sample_1.shape)\n",
    "squeezed_sample_1 = tf.squeeze(expand_sample_1)\n",
    "print(\"data size after dimension squeezing:\", squeezed_sample_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (2, 3)\n",
      "size of transposed data: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Input the tensor to be transposed, and call tf.transpose.\n",
    "trans_sample_1 = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
    "print(\"size of the original data:\", trans_sample_1.shape)\n",
    "transposed_sample_1 = tf.transpose(trans_sample_1)\n",
    "print(\"size of transposed data:\", transposed_sample_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (4, 100, 200, 3)\n",
      "size of transposed data: (4, 200, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# perm is required for high-dimensional data transpose, and indicates the dimension sequence of the input tensor.\n",
    "# The original dimension sequence of a three-dimensional tensor is [0, 1, 2] (perm), indicating the length, width, and height of high-dimensional data, respectively.\n",
    "# Data dimensions can be transposed by changing the sequence of values in perm.\n",
    "# Generate an $ x 100 x 200 x 3 tensor to represent four 100 x 200 three-channel color images.\n",
    "trans_sample_2 = tf.random.normal([4, 100, 200, 3])\n",
    "print(\"size of the original data:\", trans_sample_2.shape)\n",
    "# Exchange the length and width for the four images: The original perm value is [0,1,2,3], and the new perm value is [0,2,1,3].\n",
    "transposed_sample_2 = tf.transpose(trans_sample_2, [0, 2, 1, 3])\n",
    "print(\"size of transposed data:\", transposed_sample_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### 1.2.1.3.6  Broadcast (broadcast_to)\n",
    "- broadcast_to is used to broadcast data from a low dimension to a high dimension.\n",
    "  - tf.broadcast_to(input,shape,name=None):\n",
    "    - input: input tensor\n",
    "    - shape: size of the output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data: [1 2 3 4 5 6]\n",
      "broadcasted data: [[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "broadcast_sample_1 = tf.constant([1, 2, 3, 4, 5, 6])\n",
    "print(\"original data:\", broadcast_sample_1.numpy())\n",
    "broadcasted_sample_1 = tf.broadcast_to(broadcast_sample_1, shape=[4, 6])\n",
    "print(\"broadcasted data:\", broadcasted_sample_1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [11 12 13]\n",
      " [21 22 23]\n",
      " [31 32 33]], shape=(4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# During the operation, if two arrays have different shapes, TensorFlow automatically triggers the broadcast mechanism as NumPy does.\n",
    "a = tf.constant([[0, 0, 0], [10, 10, 10], [20, 20, 20], [30, 30, 30]])\n",
    "b = tf.constant([1, 2, 3])\n",
    "print(a + b)\n",
    "\n",
    "#### 1.2.1.4  Arithmetic Operations on Tensors\n",
    "##### 1.2.1.4.1  Arithmetic Operators\n",
    "# Main arithmetic operations include addition (tf.add), subtraction (tf.subtract), multiplication (tf.multiply), division (tf.divide), logarithm (tf.math.log), and powers (tf.pow).\n",
    "# The following describes only one addition example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 4 11]\n",
      " [ 6 17]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[3, 5], [4, 8]])\n",
    "b = tf.constant([[1, 6], [2, 9]])\n",
    "print(tf.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### 1.2.1.4.2  Matrix Multiplication\n",
    "Matrix multiplication is implemented by calling tf.matmul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[13, 63],\n",
       "       [20, 96]], dtype=int32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### 1.2.1.4.3  Tensor Statistics Collection\n",
    "- Methods for collecting tensor statistics include:\n",
    "  - tf.reduce_min/max/mean(): calculates the minimum, maximum, and mean values.\n",
    "  - tf.argmax()/tf.argmin(): calculates the positions of the maximum and minimum values.\n",
    "  - tf.equal(): checks whether two tensors are equal by element.\n",
    "  - tf.unique(): removes duplicate elements from tensors.\n",
    "  - tf.nn.in_top_k(prediction, target, K): calculates whether the predicted value is equal to the actual value, and returns a Boolean tensor.\n",
    "- The following describes how to use tf.argmax():\n",
    "  - Return the position of the maximum value.\n",
    "    - tf.argmax(input,axis):\n",
    "      - input: input tensor\n",
    "      - axis: maximum output value in the axis dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor: [[1 3 2]\n",
      " [2 5 8]\n",
      " [7 5 9]]\n",
      "locate the maximum value by column: [2 1 2]\n",
      "locate the maximum value by row: [1 2 2]\n"
     ]
    }
   ],
   "source": [
    "argmax_sample_1 = tf.constant([[1, 3, 2], [2, 5, 8], [7, 5, 9]])\n",
    "print(\"input tensor:\", argmax_sample_1.numpy())\n",
    "max_sample_1 = tf.argmax(argmax_sample_1, axis=0)\n",
    "max_sample_2 = tf.argmax(argmax_sample_1, axis=1)\n",
    "print(\"locate the maximum value by column:\", max_sample_1.numpy())\n",
    "print(\"locate the maximum value by row:\", max_sample_2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "### 1.2.1.5  Dimension-based Arithmetic Operations\n",
    "- In TensorFlow, a series of operations of tf.reduce_* reduce tensor dimensions. The series of operations can be performed on dimensional elements of a tensor, for example, calculating the mean value by row and calculating a product of all elements in the tensor.\n",
    "- Common operations include tf.reduce_sum (addition), tf.reduce_prod (multiplication), tf.reduce_min (minimum), tf.reduce_max (maximum), tf.reduce_mean (mean value), tf.reduce_all (logical AND), tf.reduce_any (logical OR), and tf.reduce_logsumexp (log(sum(exp))).\n",
    "- The methods for using these operations are similar. The following describes how to use tf.reduce_sum.\n",
    "- Calculate the sum of elements in all dimensions of a tensor.\n",
    "  - tf.reduce_sum(input_tensor, axis=None, keepdims=False,name=None):\n",
    "    - input_tensor: input tensor\n",
    "    - axis: axis to be calculated. If this parameter is not specified, the mean value of all elements is calculated.\n",
    "    - keepdims: indicates whether to keep dimensions. If this parameter is set to True, the output result retains the shape of the input tensor. If this parameter is set to False, dimensions of the output result decrease.\n",
    "    - name: operation name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data [[1 2 3]\n",
      " [4 5 6]]\n",
      "calculate the sum of all elements in the tensor (axis = None):  21\n",
      "calculate the sum of elements in each column by column (axis = 0):  [5 7 9]\n",
      "calculate the sum of elements in each column by row (axis = 1):  [ 6 15]\n"
     ]
    }
   ],
   "source": [
    "reduce_sample_1 = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
    "print(\"original data\", reduce_sample_1.numpy())\n",
    "print(\n",
    "    \"calculate the sum of all elements in the tensor (axis = None): \",\n",
    "    tf.reduce_sum(reduce_sample_1, axis=None).numpy(),\n",
    ")\n",
    "print(\n",
    "    \"calculate the sum of elements in each column by column (axis = 0): \",\n",
    "    tf.reduce_sum(reduce_sample_1, axis=0).numpy(),\n",
    ")\n",
    "print(\n",
    "    \"calculate the sum of elements in each column by row (axis = 1): \",\n",
    "    tf.reduce_sum(reduce_sample_1, axis=1).numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "### 1.2.1.6  Tensor Concatenation and Splitting\n",
    "#### 1.2.1.6.1  Tensor Concatenation\n",
    "- In TensorFlow, tensor concatenation operations include:\n",
    "  - tf.contact(): concatenates vectors based on the specified dimension, while keeping other dimensions unchanged.\n",
    "  - tf.stack(): changes a group of R dimensional tensors to R+1 dimensional tensors, with the dimensions changed after the concatenation.\n",
    "tf-ncat(values, axis, name='concat'):\n",
    "  - values: input tensor\n",
    "  - axis: dimension to concatenate\n",
    "  - name: operation name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes of the original data: (4, 100, 100, 3) (40, 100, 100, 3)\n",
      "size of the concatenated data: (44, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "concat_sample_1 = tf.random.normal([4, 100, 100, 3])\n",
    "concat_sample_2 = tf.random.normal([40, 100, 100, 3])\n",
    "print(\"sizes of the original data:\", concat_sample_1.shape, concat_sample_2.shape)\n",
    "concated_sample_1 = tf.concat([concat_sample_1, concat_sample_2], axis=0)\n",
    "print(\"size of the concatenated data:\", concated_sample_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "A dimension can be added to an original matrix in the same way. axis determines the position of the dimension.\n",
    "  - tf.stack(values, axis=0, name='stack'):\n",
    "    - values: input tensors, a group of tensors with the same shape and data type\n",
    "    - axis: dimension to concatenate\n",
    "    - name: operation name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes of the original data:  (100, 100, 3) (100, 100, 3)\n",
      "size of the concatenated data: (2, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "stack_sample_1 = tf.random.normal([100, 100, 3])\n",
    "stack_sample_2 = tf.random.normal([100, 100, 3])\n",
    "print(\"sizes of the original data: \", stack_sample_1.shape, stack_sample_2.shape)\n",
    "# Dimensions increase after the concatenation. If axis is set to 0, a dimension is added before the first dimension.\n",
    "stacked_sample_1 = tf.stack([stack_sample_1, stack_sample_2], axis=0)\n",
    "print(\"size of the concatenated data:\", stacked_sample_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "#### 1.2.1.6.2  Tensor Splitting\n",
    "- In TensorFlow, tensor splitting operations include:\n",
    "  - tf.unstack(): splits a tensor by a specific dimension.\n",
    "  - tf.split(): splits a tensor into a specified number of sub tensors based on a specific dimension.\n",
    "- tf.split() is more flexible than tf.unstack().\n",
    "- tf.unstack(value,num=None,axis=0,name='unstack'):\n",
    "  - value: input tensor\n",
    "  - num: indicates that a list containing num elements is output. The value of num must be the same as the number of elements in the specified dimension. This parameter can generally be ignored.\n",
    "  - axis: specifies the dimension based on which the tensor is split.\n",
    "  - name: operation name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[-1.0016253 ,  0.26051822,  1.7687274 ],\n",
       "         [-0.50249374, -0.3258857 , -2.0099938 ],\n",
       "         [-0.7239237 ,  0.70923704, -1.1537834 ],\n",
       "         ...,\n",
       "         [-2.192112  , -0.46967924, -0.14267786],\n",
       "         [ 0.4953367 , -0.5268708 ,  2.0384674 ],\n",
       "         [-1.0021414 ,  1.3635811 , -0.82752   ]],\n",
       " \n",
       "        [[ 0.27292117,  0.4977804 , -0.27335963],\n",
       "         [-1.8584898 , -0.99906325,  0.7514743 ],\n",
       "         [ 1.7238576 , -0.37615556,  0.7526632 ],\n",
       "         ...,\n",
       "         [ 0.29846996,  1.3420974 , -0.62700534],\n",
       "         [-0.537686  , -0.05188088, -2.4036608 ],\n",
       "         [-0.52722794,  1.2681376 , -0.35410273]],\n",
       " \n",
       "        [[ 1.0604855 ,  0.69024026,  1.1821338 ],\n",
       "         [ 0.8687667 ,  0.13040993, -0.68880635],\n",
       "         [ 0.6510132 , -0.9828226 , -0.24002507],\n",
       "         ...,\n",
       "         [-0.81382203,  0.23761371,  0.01619843],\n",
       "         [ 0.56032425,  0.78772515, -0.4091408 ],\n",
       "         [ 0.85448205, -0.5573653 ,  0.48012656]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.5707959 , -0.8067887 , -0.36198688],\n",
       "         [ 0.9101941 , -1.0773939 ,  1.3911456 ],\n",
       "         [ 0.27906206,  0.91555077,  0.46365875],\n",
       "         ...,\n",
       "         [ 0.07699841, -0.04149196,  0.22482203],\n",
       "         [-0.8504987 , -0.6557944 , -1.5299047 ],\n",
       "         [-0.98838097,  2.3322031 ,  1.7781205 ]],\n",
       " \n",
       "        [[-0.02581153,  1.1747358 , -0.72799593],\n",
       "         [-0.26113248, -0.04158615,  0.52267987],\n",
       "         [-1.5298289 , -1.1033086 , -0.93796796],\n",
       "         ...,\n",
       "         [-1.3396977 ,  0.17366903,  0.14625363],\n",
       "         [-1.2907493 , -1.8744498 , -0.3848913 ],\n",
       "         [-1.4083624 ,  2.5364122 ,  0.76750207]],\n",
       " \n",
       "        [[-0.7661501 , -1.7720944 , -0.14906965],\n",
       "         [-0.00290677, -0.23232122, -2.2018547 ],\n",
       "         [-0.3869226 , -0.73054624, -0.11577705],\n",
       "         ...,\n",
       "         [-0.25128886,  0.5216313 , -0.7881447 ],\n",
       "         [ 0.6910776 , -0.94686174,  1.0493011 ],\n",
       "         [ 0.66565454, -0.05624274,  2.047198  ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[ 1.0195689 , -0.7774001 ,  1.8349929 ],\n",
       "         [-0.08527628,  1.0653334 ,  1.6901914 ],\n",
       "         [-0.7829804 ,  0.39883435, -1.0163108 ],\n",
       "         ...,\n",
       "         [-0.10200195, -0.5067574 ,  1.0339948 ],\n",
       "         [ 1.5424936 ,  0.34807438, -1.7929115 ],\n",
       "         [ 0.8912515 , -2.314535  ,  0.27511743]],\n",
       " \n",
       "        [[-0.1547561 ,  1.2867604 ,  1.0583034 ],\n",
       "         [-1.0072061 , -0.5626375 ,  0.526538  ],\n",
       "         [ 0.19291128,  0.85545456, -0.04032563],\n",
       "         ...,\n",
       "         [-0.12633209,  1.5801452 , -0.04416031],\n",
       "         [-1.4299669 ,  1.0293078 , -0.28685176],\n",
       "         [ 0.6145202 , -0.77444047,  0.7061424 ]],\n",
       " \n",
       "        [[-0.8446159 ,  0.4450471 ,  1.4923761 ],\n",
       "         [-0.31356838, -0.86952496, -0.03889213],\n",
       "         [-0.03833674, -1.0310261 , -0.5058013 ],\n",
       "         ...,\n",
       "         [ 0.49577975, -0.81070805,  0.9041748 ],\n",
       "         [ 2.302055  , -0.75020766,  0.494866  ],\n",
       "         [ 1.1627448 , -1.2826486 , -0.05286115]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.98481846,  0.98001933,  0.85523087],\n",
       "         [ 0.7042368 , -2.301715  ,  0.28769174],\n",
       "         [ 0.33105186,  0.1419154 ,  1.2532496 ],\n",
       "         ...,\n",
       "         [ 0.04672274,  1.3085153 , -0.34082112],\n",
       "         [-0.6712063 ,  0.15264943, -0.7838137 ],\n",
       "         [-0.9392513 , -1.2023668 ,  0.29824173]],\n",
       " \n",
       "        [[-0.04152177,  1.3126976 , -0.0121173 ],\n",
       "         [-0.3842586 ,  1.1969266 , -0.52169186],\n",
       "         [ 0.69551986,  1.6084034 ,  1.1416892 ],\n",
       "         ...,\n",
       "         [ 0.29476374, -0.04981952, -0.51948416],\n",
       "         [ 1.1613482 , -1.353676  , -0.43213078],\n",
       "         [ 1.3969519 ,  0.42506713,  1.8769623 ]],\n",
       " \n",
       "        [[ 0.25001356, -1.6565068 ,  0.0798419 ],\n",
       "         [ 1.1491861 , -0.5149879 ,  1.3057618 ],\n",
       "         [ 0.64736843, -0.34220836, -1.6422296 ],\n",
       "         ...,\n",
       "         [-0.00333182,  0.49798557,  0.17340961],\n",
       "         [-1.0845822 ,  0.08793328,  1.915114  ],\n",
       "         [ 0.49164852,  1.0876532 , -1.5257612 ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data based on the first dimension and output the split data in a list.\n",
    "tf.unstack(stacked_sample_1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "- tf.split(value, num_or_size_splits, axis=0):\n",
    "  - value: input tensor\n",
    "  - num_or_size_splits: number of sub tensors\n",
    "  - axis: specifies the dimension based on which the tensor is split.\n",
    "tf-lit() splits a tensor in either of the following ways:\n",
    "  - If the value of num_or_size_splits is an integer, the tensor is evenly split into sub tensors in the specified dimension (axis = D).\n",
    "  - If the value of num_or_size_splits is a vector, the tensor is split into sub tensors based on the element value of the vector in the specified dimension (axis = D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (10, 100, 100, 3)\n",
      "size of the split data when m_or_size_splits is set to 10:  (5, 2, 100, 100, 3)\n",
      "sizes of the split data when num_or_size_splits is set to [3,5,2]: (3, 100, 100, 3) (5, 100, 100, 3) (2, 100, 100, 3)\n",
      "sizes of the split data when num_or_size_splits is set to [8,2]: (8, 100, 100, 3) (2, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "split_sample_1 = tf.random.normal([10, 100, 100, 3])\n",
    "print(\"size of the original data:\", split_sample_1.shape)\n",
    "splited_sample_1 = tf.split(split_sample_1, num_or_size_splits=5, axis=0)\n",
    "print(\n",
    "    \"size of the split data when m_or_size_splits is set to 10: \",\n",
    "    np.shape(splited_sample_1),\n",
    ")\n",
    "splited_sample_2 = tf.split(split_sample_1, num_or_size_splits=[3, 5, 2], axis=0)\n",
    "print(\n",
    "    \"sizes of the split data when num_or_size_splits is set to [3,5,2]:\",\n",
    "    np.shape(splited_sample_2[0]),\n",
    "    np.shape(splited_sample_2[1]),\n",
    "    np.shape(splited_sample_2[2]),\n",
    ")\n",
    "splited_sample_3 = tf.split(split_sample_1, num_or_size_splits=[8, 2], axis=0)\n",
    "print(\n",
    "    \"sizes of the split data when num_or_size_splits is set to [8,2]:\",\n",
    "    np.shape(splited_sample_3[0]),\n",
    "    np.shape(splited_sample_3[1]),\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "### 1.2.1.7  Tensor Sorting\n",
    "- In TensorFlow, tensor sorting operations include:\n",
    "  - tf.sort(): sorts tensors in ascending or descending order and returns the sorted tensors.\n",
    "  - tf.argsort(): sorts tensors in ascending or descending order, and returns tensor indexes.\n",
    "  - tf.nn.top_k(): returns the first k maximum values.\n",
    "tf-rt/argsort(input, direction, axis):\n",
    "  - input: input tensor\n",
    "  - direction: sorting order, which can be set to DESCENDING (descending order) or ASCENDING (ascending order). The default value is ASCENDING.\n",
    "  - axis: sorting by the dimension specified by axis. The default value of axis is –1, indicating the last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor: [8 6 9 7 5 3 0 2 4 1]\n",
      "tensor sorted in ascending order: [0 1 2 3 4 5 6 7 8 9]\n",
      "indexes of elements in ascending order: [6 9 7 5 8 4 1 3 0 2]\n"
     ]
    }
   ],
   "source": [
    "sort_sample_1 = tf.random.shuffle(tf.range(10))\n",
    "print(\"input tensor:\", sort_sample_1.numpy())\n",
    "sorted_sample_1 = tf.sort(sort_sample_1, direction=\"ASCENDING\")\n",
    "print(\"tensor sorted in ascending order:\", sorted_sample_1.numpy())\n",
    "sorted_sample_2 = tf.argsort(sort_sample_1, direction=\"ASCENDING\")\n",
    "print(\"indexes of elements in ascending order:\", sorted_sample_2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "- tf.nn.top_k(input,K,sorted=TRUE):\n",
    "  - input: input tensor\n",
    "  - K: the first k values to be output and their indexes\n",
    "  - sorted: When sorted is set to TRUE, the tensor is sorted in ascending order. When sorted is set to FALSE, the tensor is sorted in descending order.\n",
    "Re-n two tensors:\n",
    "  - values: k maximum values in each row\n",
    "  - indices: positions of elements in the last dimension of the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor: [8 6 9 7 5 3 0 2 4 1]\n",
      "first five values in ascending order: [9 8 7 6 5]\n",
      "indexes of the first five values in ascending order: [2 0 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "values, index = tf.nn.top_k(sort_sample_1, 5)\n",
    "print(\"input tensor:\", sort_sample_1.numpy())\n",
    "print(\"first five values in ascending order:\", values.numpy())\n",
    "print(\"indexes of the first five values in ascending order:\", index.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.2.2  Eager Execution of TensorFlow 2.x\n",
    "- The eager execution mode of TensorFlow is a type of imperative programming, which is the same as native Python. When you perform a particular operation, the system immediately returns a result.\n",
    "- Graph mode:\n",
    "- TensorFlow 1.0 adopts the graph mode to first build a computational graph, enable a session, and then feed actual data to obtain a result.\n",
    "- In eager execution mode, code debugging is easier, but the code execution efficiency is lower.\n",
    "- The following implements simple multiplication by using TensorFlow to compare the differences between the eager execution mode and the graph mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((2, 2), dtype=tf.dtypes.float32)\n",
    "y = tf.constant([[1, 2], [3, 4]], dtype=tf.dtypes.float32)\n",
    "z = tf.matmul(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 6.]\n",
      " [4. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# Use the syntax of TensorFlow 1.x in TensorFlow 2.x. You can install the v1 compatibility package in TensorFlow 2.0 to inherit the TensorFlow 1.x code and disable the eager execution mode.\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "# Create a graph and define it as a computational graph.\n",
    "a = tf.ones((2, 2), dtype=tf.dtypes.float32)\n",
    "b = tf.constant([[1, 2], [3, 4]], dtype=tf.dtypes.float32)\n",
    "c = tf.matmul(a, b)\n",
    "a\n",
    "b\n",
    "\n",
    "\n",
    "# Enable the drawing function, and perform the multiplication operation to obtain data.\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Restart the kernel to restore TensorFlow 2.0 and enable the eager execution mode. Another advantage of the eager execution mode lies in availability of native Python functions, for example, the following condition statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.010016441, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "thre_1 = tf.random.uniform([], 0, 1)\n",
    "x = tf.reshape(tf.range(0, 4), [2, 2])\n",
    "print(thre_1)\n",
    "if thre_1.numpy() > 0.5:\n",
    "    y = tf.matmul(x, x)\n",
    "else:\n",
    "    y = tf.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "With the eager execution mode, this dynamic control flow can generate a NumPy value extractable by a tensor, without using operators such as tf.cond and tf.while provided in graph mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "\n",
    "## 1.2.3  AutoGraph of TensorFlow 2.x\n",
    "When used to comment out a function, the decorator tf.function can be called like any other function. tf.function will be compiled into a graph, so that it can run more efficiently on a GPU or TPU. In this case, the function becomes an operation in TensorFlow. The function can be directly called to output a return value. However, the function is executed in graph mode and intermediate variable values cannot be directly viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"b:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1.0012102, 0.8567029, 1.0545027],\n",
       "       [1.2461724, 1.7495183, 1.3102707],\n",
       "       [1.2327646, 1.6710498, 1.3720185]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_nn_layer(w, x, b):\n",
    "    print(b)\n",
    "    return tf.nn.relu(tf.matmul(w, x) + b)\n",
    "\n",
    "\n",
    "w = tf.random.uniform((3, 3))\n",
    "x = tf.random.uniform((3, 3))\n",
    "b = tf.constant(0.5, dtype=\"float32\")\n",
    "\n",
    "simple_nn_layer(w, x, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the output result, the value of b in the function cannot be viewed directly, but the return value can be viewed using .numpy().\n",
    "The following compares the performance of the graph mode and eager execution mode by performing the same operation (computation of one CNN layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode: 0.004066933004651219\n",
      "time required for performing the computation of one CNN layer in graph mode: 0.0027632830024231225\n"
     ]
    }
   ],
   "source": [
    "# Use the timeit module to measure the execution time of a small code segment.\n",
    "import timeit\n",
    "\n",
    "# Create a convolutional layer.\n",
    "CNN_cell = tf.keras.layers.Conv2D(filters=32, kernel_size=2, strides=(1, 1))\n",
    "\n",
    "# Use @tf.function to convert the operation into a graph.\n",
    "@tf.function\n",
    "def CNN_fn(image):\n",
    "    return CNN_cell(image)\n",
    "\n",
    "\n",
    "image = tf.zeros([100, 200, 200, 3])\n",
    "\n",
    "# Compare the execution time of the two modes.\n",
    "CNN_cell(image)\n",
    "CNN_fn(image)\n",
    "# Call timeit.timeit to measure the time required for executing the code 10 times.\n",
    "print(\n",
    "    \"time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode:\",\n",
    "    timeit.timeit(lambda: CNN_cell(image), number=10),\n",
    ")\n",
    "print(\n",
    "    \"time required for performing the computation of one CNN layer in graph mode:\",\n",
    "    timeit.timeit(lambda: CNN_fn(image), number=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "The comparison shows that the code execution efficiency in graph mode is much higher. Therefore, the @tf.function function can be used to improve the code execution efficiency."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
