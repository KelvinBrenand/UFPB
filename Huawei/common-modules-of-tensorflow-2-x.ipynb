{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1  Introduction\n",
    "- This section describes the common modules of TensorFlow 2.x, including:\n",
    "  - tf.data: implements operations on datasets.\n",
    "- These operations include reading datasets directly from the memory, reading CSV files, reading TFRecord files, and augmenting data.\n",
    "  - tf.image: implements processing operations on images.\n",
    "- These operations include image luminance transformation, saturation transformation, image size transformation, image rotation, and edge detection.\n",
    "  - tf.gfile: implements operations on files.\n",
    "- These operations include reading, writing, and renaming files, and operating folders.\n",
    "  - tf.keras: a high-level API used to build and train deep learning models.\n",
    "  - tf.distributions and other modules\n",
    "- This section focuses on the tf.keras module to lay a foundation for deep learning modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 2.2  Objectives\n",
    "- Upon completion of this task, you will be able to master the common deep learning modeling interfaces in tf.keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# 2.3  Experiment Steps\n",
    "### 2.3.1  Model Building\n",
    "#### 2.3.1.1  Stacking a Model (tf.keras.Sequential)\n",
    "- The most common way to build a model is to stack layers by using tf.keras.Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1.2  Building a Functional Model\n",
    "- Functional models are mainly built by using tf.keras.Input and tf.keras.Model, which are more complex than tf.keras.Sequential but have a good effect. Variables can be input at the same time or in different phases, and data can be output in different phases. Functional models are preferred if more than one model output is needed.\n",
    "- Stacked model (.Sequential) vs. functional model (.Model):\n",
    "- The tf.keras.Sequential model is a simple stack of layers that cannot represent arbitrary models. You can use the Keras functional API to build complex model topologies such as:\n",
    "  - Multi-input models\n",
    "  - Multi-output models\n",
    "  - Models with shared layers\n",
    "  - Models with non-sequential data flows (for example, residual connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 2,442\n",
      "Trainable params: 2,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use the output of the previous layer as the input of the next layer.\n",
    "x = tf.keras.Input(shape=(32,))\n",
    "h1 = layers.Dense(32, activation=\"relu\")(x)\n",
    "h2 = layers.Dense(32, activation=\"relu\")(h1)\n",
    "y = layers.Dense(10, activation=\"softmax\")(h2)\n",
    "model_sample_2 = tf.keras.models.Model(x, y)\n",
    "\n",
    "# Print model information.\n",
    "model_sample_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1.3  Building a Network Layer (tf.keras.layers)\n",
    "- The tf.keras.layers module is used to configure neural network layers. Common classes include:\n",
    "  - tf.keras.layers.Dense: builds a fully connected layer.\n",
    "  - tf.keras.layers.Conv2D: builds a two-dimensional convolutional layer.\n",
    "  - tf.keras.layers.MaxPooling2D/AveragePooling2D: builds a maximum/average pooling layer.\n",
    "  - tf.keras.layers.RNN: builds a recurrent neural network layer.\n",
    "  - tf.keras.layers.LSTM/tf.keras.layers.LSTMCell: builds an LSTM network layer/LSTM unit.\n",
    "  - tf.keras.layers.GRU/tf.keras.layers.GRUCell: builds a GRU unit/GRU network layer.\n",
    "  - tf.keras.layers.Embedding: converts a positive integer (subscript) into a vector of a fixed size, for example, converts [[4], [20]] into [[0.25, 0.1], [0.6, â€“0.2]]. The embedding layer can be used only as the first model layer.\n",
    "  - tf.keras.layers.Dropout: builds the dropout layer.\n",
    "- The following describes tf.keras.layers.Dense, tf.keras.layers.Conv2D, tf.keras.layers.MaxPooling2D/AveragePooling2D, and tf.keras.layers.LSTM/tf.keras.layers.LSTMCell.\n",
    "- Main network configuration parameters in tf.keras.layers include:\n",
    "  - activation: sets the activation function for the layer. By default, the system applies no activation function.\n",
    "  - kernel_initializer and bias_initializer: initialization schemes that create the layer's weights (kernel and bias). This defaults to the Glorot uniform initializer.\n",
    "  - kernel_regularizer and bias_regularizer: regularization schemes that apply to the layer's weights (kernel and bias), such as L1 or L2 regularization. By default, the system applies no regularization function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "##### 2.3.1.3.1  tf.keras.layers.Dense\n",
    "- Main configuration parameters in tf.keras.layers.Dense include:\n",
    "  - units: number of neurons\n",
    "  - activation: sets the activation function.\n",
    "  - use_bias: indicates whether to use bias terms. Bias terms are used by default.\n",
    "  - kernel_initializer: initialization scheme that creates the layer's weight (kernel)\n",
    "  - bias_initializer: initialization scheme that creates the layer's weight (bias)\n",
    "  - kernel_regularizer: regularization scheme that applies to the layer's weight (kernel)\n",
    "  - bias_regularizer: regularization scheme that applies to the layer's weight (bias)\n",
    "  - activity_regularizer: regular item applied to the output, a regularizer object\n",
    "  - kernel_constraint: a constraint applied to a weight\n",
    "  - bias_constraint: a constraint applied to a weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7eff94878100>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fully connected layer that contains 32 neurons. Set the activation function to sigmoid.\n",
    "# The activation parameter can be set to a function name string, for example, sigmoid or a function object, for example, tf.sigmoid.\n",
    "layers.Dense(32, activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7eff2c149880>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(32, activation=tf.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7eff2c1126d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set kernel_initializer.\n",
    "layers.Dense(32, kernel_initializer=tf.keras.initializers.he_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7eff2c1496d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set kernel_regularizer to L2 regularization.\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "##### 2.3.1.3.2  tf.keras.layers.Conv2D\n",
    "- Main configuration parameters in tf.keras.layers.Conv2D include:\n",
    "  - filters: number of convolution kernels (output dimensions)\n",
    "  - kernel_size: width and length of a convolution kernel\n",
    "  - strides: convolution step\n",
    "  - padding: zero padding policy\n",
    "- When padding is set to valid, only valid convolution is performed, that is, boundary data is not processed. When padding is set to same, the convolution result at the boundary is reserved, and consequently, the output shape is usually the same as the input shape.\n",
    "  - activation: sets the activation function.\n",
    "  - data_format: data format, set to channels_first or channels_last. For example, for a 128 x 128 RGB image, data is organized as (3, 128, 128) if the value is channels_first, and (128, 128, 3) if the value is channels_last. The default value of this parameter is the value specified in ~/.keras/keras.json. If this parameter has never been set, the default value is channels_last.\n",
    "- Other parameters include use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraints, and bias_constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7eff2c0bc5e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Conv2D(64, [1, 1], 2, padding=\"same\", activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "##### 2.3.1.3.3  tf.keras.layers.MaxPooling2D/AveragePooling2D\n",
    "- Main configuration parameters in tf.keras.layers.MaxPooling2D/AveragePooling2D include:\n",
    "  - pool_size: size of the pooled kernel. For example, if the matrix (2, 2) is used, the picture becomes half of the original length in both dimensions. If this parameter is set to an integer, the integer is the values of all dimensions.\n",
    "  - strides: step\n",
    "- Other parameters include padding and data_format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7eff2c0bc190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "##### 2.3.1.3.4  tf.keras.layers.LSTM/tf.keras.layers.LSTMCell\n",
    "- Main configuration parameters in tf.keras.layers.LSTM/tf.keras.layers.LSTMCell include:\n",
    "  - units: output dimension\n",
    "  - input_shape (timestep and input_dim): timestep can be set to None, and input_dim indicates the input data dimension.\n",
    "  - activation: sets the activation function.\n",
    "  - recurrent_activation: activation function to use for the recurrent step\n",
    "  - return_sequences: If the value is True, the system returns the full sequence. If the value is False, the system returns the output in the last cell of the output sequence.\n",
    "  - return_state: Boolean value, indicating whether to return the last state in addition to the output.\n",
    "  - dropout: float between 0 and 1, fraction of the neurons to drop for the linear transformation of the inputs.\n",
    "  - recurrent_dropout: float between 0 and 1, fraction of the neurons to drop for the linear transformation of the recurrent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.1], [0.2], [0.3]]]\n",
      "output when return_sequences is set to True [[[-0.01703078]\n",
      "  [-0.04257001]\n",
      "  [-0.07225549]]]\n",
      "output when return_sequences is set to False [[-0.03124596]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = tf.keras.Input(shape=(3, 1))\n",
    "lstm = layers.LSTM(1, return_sequences=True)(inputs)\n",
    "model_lstm_1 = tf.keras.models.Model(inputs=inputs, outputs=lstm)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(3, 1))\n",
    "lstm = layers.LSTM(1, return_sequences=False)(inputs)\n",
    "model_lstm_2 = tf.keras.models.Model(inputs=inputs, outputs=lstm)\n",
    "\n",
    "# Sequences t1, t2, and t3\n",
    "data = [[[0.1], [0.2], [0.3]]]\n",
    "print(data)\n",
    "print(\"output when return_sequences is set to True\", model_lstm_1.predict(data))\n",
    "print(\"output when return_sequences is set to False\", model_lstm_2.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "- LSTMcell is the implementation unit of the LSTM layer.\n",
    "  - LSTM is an LSTM network layer.\n",
    "  - LSTMcell is a single-step computing unit, that is, an LSTM unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# LSTM\n",
    "tf.keras.layers.LSTM(16, return_sequences=True)\n",
    "\n",
    "# LSTMCell\n",
    "x = tf.keras.Input((None, 3))\n",
    "y = layers.RNN(layers.LSTMCell(16))(x)\n",
    "model_lstm_3 = tf.keras.Model(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 2.3.2  Training and Evaluation\n",
    "### 2.3.2.1  Model Compilation\n",
    "\n",
    "- After a model is built, you can call compile to configure the learning process of the model:\n",
    "  - compile( optimizer='rmsprop', loss=None, metrics=None, loss_weights=None):\n",
    "      - optimizer: optimizer\n",
    "      - loss: loss function, cross entropy for binary tasks and MSE for regression tasks\n",
    "      - metrics: model evaluation criteria during training and testing For example, metrics can be set to ['accuracy']. To specify multiple evaluation criteria, set a dictionary, for example, set metrics to {'output_a':'accuracy'}.\n",
    "      - loss_weights: If the model has multiple task outputs, you need to specify a weight for each output when optimizing the global loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "# Determine the optimizer (optimizer), loss function (loss), and model evaluation method (metrics).\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    metrics=[tf.keras.metrics.categorical_accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### 2.3.2.2  Model Training\n",
    "- fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None):\n",
    "  - x: input training data\n",
    "  - y: target (labeled) data\n",
    "  - batch_size: number of samples for each gradient update The default value is 32.\n",
    "  - epochs: number of iteration rounds of the training model\n",
    "  - verbose: log display mode, set to 0, 1, or 2.\n",
    "      - 0: no display\n",
    "      - 1: progress bar\n",
    "      - 2: one line for each round\n",
    "  - callbacks: callback function used during training\n",
    "  - validation_split: fraction of the training data to be used as validation data\n",
    "  - validation_data: validation set. This parameter will overwrite validation_split.\n",
    "  - shuffle: indicates whether to shuffle data before each round of iteration. This parameter is invalid when steps_per_epoch is not None.\n",
    "  - initial_epoch: epoch at which to start training (useful for resuming a previous training weight)\n",
    "  - steps_per_epoch: set to the dataset size or batch_size\n",
    "  - validation_steps: Total number of steps (batches of samples) to validate before stopping. This parameter is valid only when steps_per_epoch is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 12.9379 - categorical_accuracy: 0.0910 - val_loss: 12.7422 - val_categorical_accuracy: 0.1200\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9366 - categorical_accuracy: 0.0910 - val_loss: 12.7414 - val_categorical_accuracy: 0.1200\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 12.9348 - categorical_accuracy: 0.0900 - val_loss: 12.7387 - val_categorical_accuracy: 0.1200\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9320 - categorical_accuracy: 0.0900 - val_loss: 12.7362 - val_categorical_accuracy: 0.1200\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9292 - categorical_accuracy: 0.0900 - val_loss: 12.7337 - val_categorical_accuracy: 0.1200\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9299 - categorical_accuracy: 0.0900 - val_loss: 12.7358 - val_categorical_accuracy: 0.1200\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9287 - categorical_accuracy: 0.0910 - val_loss: 12.7326 - val_categorical_accuracy: 0.1200\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9269 - categorical_accuracy: 0.0910 - val_loss: 12.7311 - val_categorical_accuracy: 0.1200\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9248 - categorical_accuracy: 0.0910 - val_loss: 12.7290 - val_categorical_accuracy: 0.1200\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 12.9242 - categorical_accuracy: 0.0910 - val_loss: 12.7293 - val_categorical_accuracy: 0.1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7eff0c043e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_x = np.random.random((1000, 36))\n",
    "train_y = np.random.random((1000, 10))\n",
    "val_x = np.random.random((200, 36))\n",
    "val_y = np.random.random((200, 10))\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "- You can use tf.data to build training input pipelines for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 12.9216 - categorical_accuracy: 0.0906 - val_loss: 13.1680 - val_categorical_accuracy: 0.0938\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.9373 - categorical_accuracy: 0.0876 - val_loss: 13.1606 - val_categorical_accuracy: 0.0938\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.9307 - categorical_accuracy: 0.0929 - val_loss: 13.1520 - val_categorical_accuracy: 0.0938\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.9332 - categorical_accuracy: 0.0940 - val_loss: 13.1442 - val_categorical_accuracy: 0.0938\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.8955 - categorical_accuracy: 0.0919 - val_loss: 13.1375 - val_categorical_accuracy: 0.0938\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.8823 - categorical_accuracy: 0.0908 - val_loss: 13.1304 - val_categorical_accuracy: 0.0938\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.9170 - categorical_accuracy: 0.0929 - val_loss: 13.1232 - val_categorical_accuracy: 0.0938\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.8920 - categorical_accuracy: 0.0876 - val_loss: 13.1163 - val_categorical_accuracy: 0.0938\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.8637 - categorical_accuracy: 0.0951 - val_loss: 13.1108 - val_categorical_accuracy: 0.0938\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 12.8547 - categorical_accuracy: 0.0908 - val_loss: 13.1055 - val_categorical_accuracy: 0.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7eff2dcecac0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "val_dataset = val_dataset.repeat()\n",
    "\n",
    "model.fit(\n",
    "    dataset,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=30,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### 2.3.2.3  Callback Functions\n",
    "- A callback function is an object passed to the model to customize and extend the model's behavior during training. You can customize callback functions or use embedded functions in tf.keras.callbacks. Common embedded callback functions include:\n",
    "  - tf.keras.callbacks.ModelCheckpoint: periodically saves models.\n",
    "  - tf.keras.callbacks.LearningRateScheduler: dynamically changes the learning rate.\n",
    "  - tf.keras.callbacks.EarlyStopping: stops the training in advance.\n",
    "  - tf.keras.callbacks.TensorBoard: exports and visualizes the training progress and results with TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/63 [..............................] - ETA: 0s - loss: 12.7824 - categorical_accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0039s vs `on_train_batch_end` time: 0.0140s). Check your callbacks.\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 13.0983 - categorical_accuracy: 0.0970 - val_loss: 13.3833 - val_categorical_accuracy: 0.1150\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 12.9361 - categorical_accuracy: 0.0910 - val_loss: 12.2455 - val_categorical_accuracy: 0.1100\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 12.8890 - categorical_accuracy: 0.0850 - val_loss: 12.4368 - val_categorical_accuracy: 0.1050\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 12.6524 - categorical_accuracy: 0.0900 - val_loss: 12.3193 - val_categorical_accuracy: 0.1050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efebc00bd60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set hyperparameters.\n",
    "Epochs = 10\n",
    "\n",
    "# Define a function for dynamically setting the learning rate.\n",
    "def lr_Scheduler(epoch):\n",
    "    if epoch > 0.9 * Epochs:\n",
    "        lr = 0.0001\n",
    "    elif epoch > 0.5 * Epochs:\n",
    "        lr = 0.001\n",
    "    elif epoch > 0.25 * Epochs:\n",
    "        lr = 0.01\n",
    "    else:\n",
    "        lr = 0.1\n",
    "    return lr\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    # Early stopping:\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        # Metric for determining whether the model performance has no further improvement\n",
    "        monitor=\"val_loss\",\n",
    "        # Threshold for determining whether the model performance has no further improvement\n",
    "        min_delta=1e-2,\n",
    "        # Number of epochs in which the model performance has no further improvement\n",
    "        patience=2,\n",
    "    ),\n",
    "    # Periodically save models.\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        # Model path\n",
    "        filepath=\"models/testmodel_{epoch}.h5\",\n",
    "        # Whether to save the optimal model.\n",
    "        save_best_only=True,\n",
    "        # Monitored metric\n",
    "        monitor=\"val_loss\",\n",
    "    ),\n",
    "    # Dynamically change the learning rate.\n",
    "    tf.keras.callbacks.LearningRateScheduler(lr_Scheduler),\n",
    "    # Use TensorBoard.\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"./logs\"),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    batch_size=16,\n",
    "    epochs=Epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_x, val_y),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### 2.3.2.4  Evaluation and Prediction\n",
    "- Evaluation and prediction functions: tf.keras.Model.evaluate and tf.keras.Model.predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 12.2986 - categorical_accuracy: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.298583984375, 0.0949999988079071]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation\n",
    "test_x = np.random.random((1000, 36))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09335347 0.13224547 0.07875559 ... 0.07683735 0.0268837  0.05163656]\n",
      " [0.03427786 0.18014106 0.04260743 ... 0.07630447 0.09024951 0.10001912]\n",
      " [0.12117047 0.253901   0.06177083 ... 0.06571057 0.04136733 0.06100276]\n",
      " ...\n",
      " [0.04747442 0.26787966 0.05705576 ... 0.04265461 0.04123139 0.07249597]\n",
      " [0.0562726  0.15934971 0.0230351  ... 0.09552448 0.08423833 0.09369974]\n",
      " [0.05691526 0.15668836 0.05554255 ... 0.05297967 0.06488828 0.06006315]]\n"
     ]
    }
   ],
   "source": [
    "# Model prediction\n",
    "pre_x = np.random.random((10, 36))\n",
    "result = model.predict(test_x,)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 2.3.3  Model Saving and Restoration\n",
    "### 2.3.3.1  Saving and Restoring an Entire Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Save models.\n",
    "os.makedirs(\"model\")\n",
    "model.save(\"./model/the_save_model.h5\")\n",
    "# Import models.\n",
    "new_model = tf.keras.models.load_model(\"./model/the_save_model.h5\")\n",
    "new_prediction = new_model.predict(test_x)\n",
    "# np.testing.assert_allclose: determines whether the similarity between two objects exceeds the specified tolerance. If yes, the system displays an exception.\n",
    "# atol: specified tolerance\n",
    "np.testing.assert_allclose(\n",
    "    result, new_prediction, atol=1e-6\n",
    ")  # Prediction results are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After a model is saved, you can find the corresponding weight file in the corresponding folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### 2.3.3.2  Saving and Loading Network Weights Only\n",
    "- If the weight name is suffixed with .h5 or .keras, save the weight as an HDF5 file, or otherwise, save the weight as a TensorFlow checkpoint file by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"./model/model_weights\")\n",
    "model.save_weights(\"./model/model_weights.h5\")\n",
    "# Load the weights.\n",
    "model.load_weights(\"./model/model_weights\")\n",
    "model.load_weights(\"./model/model_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
